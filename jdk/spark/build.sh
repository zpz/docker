set -o nounset
set -o pipefail

thisfile="${BASH_SOURCE[0]}"
thisdir=$( cd "$( dirname "${thisfile}" )" && pwd )
parentdir=$(dirname "${thisdir}")
parent_name=$(cat "${parentdir}"/name)
parent_version=$(cat "${parentdir}"/version)
PARENT="${parent_name}":"${parent_version}"

version=$(cat "${thisdir}"/version)
if [[ "${version}" < "${parent_version}" ]]; then
    echo "${parent_version}" > "${thisdir}"/version
    version=${parent_version}
fi
NAME="$(cat "${thisdir}/name"):${version}"

echo
echo =====================================================
echo Creating Dockerfile for "'${NAME}'"...
cat > "${thisdir}"/Dockerfile <<EOF
# Dockerfile for image '${NAME}'
# Generated by 'build.sh'
#
# DO NOT EDIT.

FROM ${PARENT}
USER root
EOF

cat >> "${thisdir}"/Dockerfile <<'EOF'

# SPARK
# How to find the latest version of spark:
# Go to official Apache Spark site, go to 'download'.
#
ENV SPARK_VERSION 2.1.1
ENV SPARK_HOME /usr/lib/spark
ARG SPARK_PACKAGE=spark-${SPARK_VERSION}-bin-hadoop2.7
RUN mkdir -p ${SPARK_HOME} \
    && curl -skL --retry 3 \
        "https://dist.apache.org/repos/dist/release/spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz" \
        | tar xz -C ${SPARK_HOME}
ENV SPARK_HOME ${SPARK_HOME}/${SPARK_PACKAGE}
ENV PATH $PATH:${SPARK_HOME}/bin

ENV SPARK_OPTS --driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info

# Noteï¼šthe env varialbes set by these ENV commands are for `root` only.
# To set global env variables, some other approach is needed.
# Hints: /etc/bash.bashrc, /etc/profile.d/, /etc/pam.d/
EOF

echo
echo Building image "'${NAME}'"
echo
docker build -t "${NAME}" "${thisdir}"


